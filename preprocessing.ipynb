{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad98b7ee",
   "metadata": {},
   "source": [
    "1. Dataset Overview\n",
    "\n",
    "Dataset Name: Delhi Traffic Density Dataset\n",
    "City: Delhi\n",
    "Data Type: Time-series traffic density data\n",
    "Granularity: Per-second measurements\n",
    "Duration: ~40 days (September to December)\n",
    "\n",
    "Each CSV file represents one day of traffic data collected using traffic cameras at a Delhi intersection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06d2766f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d69e1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CSV files: 40\n",
      "Sample files: ['Dec15.csv', 'Dec16.csv', 'Dec17.csv', 'Dec18.csv', 'Dec19.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_path = Path(\"D:\\Projects\\Traffic_flow_prediction\\data\\extracted\\DelhiTrafficDensityDataset\")\n",
    "\n",
    "files = os.listdir(data_path)\n",
    "\n",
    "print(\"Number of CSV files:\", len(files))\n",
    "print(\"Sample files:\", files[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d233d87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54001 entries, 0 to 54000\n",
      "Data columns (total 13 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   EpochTime      54001 non-null  int64  \n",
      " 1   QueueDensity1  54001 non-null  float64\n",
      " 2   StopDensity1   54001 non-null  float64\n",
      " 3   QueueDensity2  54001 non-null  float64\n",
      " 4   StopDensity2   54001 non-null  float64\n",
      " 5   QueueDensity3  54001 non-null  float64\n",
      " 6   StopDensity3   54001 non-null  float64\n",
      " 7   QueueDensity4  54001 non-null  float64\n",
      " 8   StopDensity4   54001 non-null  float64\n",
      " 9   QueueDensity5  54001 non-null  float64\n",
      " 10  StopDensity5   54001 non-null  float64\n",
      " 11  QueueDensity6  54001 non-null  float64\n",
      " 12  StopDensity6   54001 non-null  float64\n",
      "dtypes: float64(12), int64(1)\n",
      "memory usage: 5.4 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(    EpochTime  QueueDensity1  StopDensity1  QueueDensity2  StopDensity2  \\\n",
       " 0  1607995800       0.081189      0.037368       0.055712      0.053962   \n",
       " 1  1607995801       0.073563      0.054372       0.054795      0.050808   \n",
       " 2  1607995802       0.081688      0.056802       0.054722      0.038284   \n",
       " 3  1607995803       0.133200      0.084858       0.160540      0.123520   \n",
       " 4  1607995804       0.210780      0.055671       0.078904      0.054119   \n",
       " \n",
       "    QueueDensity3  StopDensity3  QueueDensity4  StopDensity4  QueueDensity5  \\\n",
       " 0       0.078610      0.076280       0.107167      0.081873       0.055056   \n",
       " 1       0.078111      0.075976       0.109480      0.082113       0.046894   \n",
       " 2       0.077518      0.075904       0.109600      0.092484       0.043800   \n",
       " 3       0.077409      0.071430       0.108866      0.086182       0.043163   \n",
       " 4       0.078076      0.076397       0.109781      0.087974       0.046313   \n",
       " \n",
       "    StopDensity5  QueueDensity6  StopDensity6  \n",
       " 0      0.011932       0.225578      0.214888  \n",
       " 1      0.012100       0.232674      0.222390  \n",
       " 2      0.011063       0.243332      0.224276  \n",
       " 3      0.011221       0.271451      0.249055  \n",
       " 4      0.028941       0.262768      0.254160  ,\n",
       " None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_file = os.path.join(data_path, files[0])\n",
    "df = pd.read_csv(sample_file)\n",
    "\n",
    "df.head(), df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "977a6b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EpochTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1607995800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1607995801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1607995802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1607995803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1607995804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    EpochTime\n",
       "0  1607995800\n",
       "1  1607995801\n",
       "2  1607995802\n",
       "3  1607995803\n",
       "4  1607995804"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['EpochTime']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6163e3",
   "metadata": {},
   "source": [
    "2: Timestamp Conversion and Dataset Merging\n",
    "In this step, all daily CSV files are loaded programmatically.\n",
    "The Unix epoch time is converted to a human-readable datetime format, and the files are merged into a single continuous time-series dataset.\n",
    "This merged dataset will serve as the base for further aggregation and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58d00d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CSV files found: 40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Dec15.csv', 'Dec16.csv', 'Dec17.csv', 'Dec18.csv', 'Dec19.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"D:\\Projects\\Traffic_flow_prediction\\data\\extracted\\DelhiTrafficDensityDataset\"\n",
    "\n",
    "csv_files = sorted([f for f in os.listdir(data_path) if f.endswith(\".csv\")])\n",
    "\n",
    "print(\"Total CSV files found:\", len(csv_files))\n",
    "csv_files[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b82ecf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Files, Convert EpochTime, and Merge\n",
    "df_list = []\n",
    "\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(data_path, file)\n",
    "    temp_df = pd.read_csv(file_path)\n",
    "\n",
    "    # Convert Unix epoch time to datetime\n",
    "    temp_df['timestamp'] = pd.to_datetime(temp_df['EpochTime'], unit='s')\n",
    "\n",
    "    df_list.append(temp_df)\n",
    "\n",
    "traffic_df = pd.concat(df_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0191591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(            timestamp\n",
       " 0 2020-09-12 01:30:00\n",
       " 1 2020-09-12 01:30:01\n",
       " 2 2020-09-12 01:30:02\n",
       " 3 2020-09-12 01:30:03\n",
       " 4 2020-09-12 01:30:04,\n",
       "                   timestamp\n",
       " 2160035 2020-12-19 16:29:56\n",
       " 2160036 2020-12-19 16:29:57\n",
       " 2160037 2020-12-19 16:29:58\n",
       " 2160038 2020-12-19 16:29:59\n",
       " 2160039 2020-12-19 16:30:00)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort Dataset by Time (CRITICAL)\n",
    "traffic_df = traffic_df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "traffic_df[['timestamp']].head(), traffic_df[['timestamp']].tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b6f22d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 2160040\n",
      "Start timestamp: 2020-09-12 01:30:00\n",
      "End timestamp: 2020-12-19 16:30:00\n",
      "\n",
      "Missing values per column:\n",
      "EpochTime        0\n",
      "QueueDensity1    0\n",
      "StopDensity1     0\n",
      "QueueDensity2    0\n",
      "StopDensity2     0\n",
      "QueueDensity3    0\n",
      "StopDensity3     0\n",
      "QueueDensity4    0\n",
      "StopDensity4     0\n",
      "QueueDensity5    0\n",
      "StopDensity5     0\n",
      "QueueDensity6    0\n",
      "StopDensity6     0\n",
      "timestamp        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Validate the Merged Dataset\n",
    "print(\"Total rows:\", traffic_df.shape[0])\n",
    "print(\"Start timestamp:\", traffic_df['timestamp'].min())\n",
    "print(\"End timestamp:\", traffic_df['timestamp'].max())\n",
    "\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(traffic_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cd4fbe",
   "metadata": {},
   "source": [
    "Outcome of STEP 2:\n",
    "All 40 daily CSV files were merged into a single dataset after converting Unix epoch timestamps to datetime format.\n",
    "The resulting dataset preserves temporal order and forms a continuous time-series suitable for further preprocessing and deep learning–based traffic flow prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938dccff",
   "metadata": {},
   "source": [
    "STEP 3: Lane-wise Aggregation and Hourly Resampling\n",
    "In this step, multiple lane-level queue density measurements are aggregated into a single traffic density signal.\n",
    "The per-second data is then resampled to hourly averages to reduce noise and create a stable time-series suitable for deep learning models such as LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff3e6317",
   "metadata": {},
   "outputs": [],
   "source": [
    "queue_density_cols = [\n",
    "    'QueueDensity1', 'QueueDensity2', 'QueueDensity3',\n",
    "    'QueueDensity4', 'QueueDensity5', 'QueueDensity6'\n",
    "]\n",
    "\n",
    "traffic_df['avg_queue_density'] = traffic_df[queue_density_cols].mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "890af747",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_density_cols = [\n",
    "    'StopDensity1', 'StopDensity2', 'StopDensity3',\n",
    "    'StopDensity4', 'StopDensity5', 'StopDensity6'\n",
    "]\n",
    "\n",
    "traffic_df['avg_stop_density'] = traffic_df[stop_density_cols].mean(axis=1)\n",
    "\n",
    "traffic_df['total_density'] = (\n",
    "    traffic_df['avg_queue_density'] + traffic_df['avg_stop_density']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61520506",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_df = traffic_df[\n",
    "    ['timestamp', 'avg_queue_density', 'avg_stop_density', 'total_density']\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da3cacd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_queue_density</th>\n",
       "      <th>avg_stop_density</th>\n",
       "      <th>total_density</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-09-12 01:30:00</th>\n",
       "      <td>0.183016</td>\n",
       "      <td>0.157407</td>\n",
       "      <td>0.340423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-12 01:30:01</th>\n",
       "      <td>0.164574</td>\n",
       "      <td>0.154453</td>\n",
       "      <td>0.319027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-12 01:30:02</th>\n",
       "      <td>0.170759</td>\n",
       "      <td>0.157478</td>\n",
       "      <td>0.328236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-12 01:30:03</th>\n",
       "      <td>0.165333</td>\n",
       "      <td>0.153652</td>\n",
       "      <td>0.318985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-12 01:30:04</th>\n",
       "      <td>0.170892</td>\n",
       "      <td>0.153040</td>\n",
       "      <td>0.323932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     avg_queue_density  avg_stop_density  total_density\n",
       "timestamp                                                              \n",
       "2020-09-12 01:30:00           0.183016          0.157407       0.340423\n",
       "2020-09-12 01:30:01           0.164574          0.154453       0.319027\n",
       "2020-09-12 01:30:02           0.170759          0.157478       0.328236\n",
       "2020-09-12 01:30:03           0.165333          0.153652       0.318985\n",
       "2020-09-12 01:30:04           0.170892          0.153040       0.323932"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_df.set_index('timestamp', inplace=True)\n",
    "traffic_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9105a18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample Per-Second Data to Hourly Average\n",
    "resampled_df = traffic_df.resample('15min').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b632139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_df.interpolate(method='time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc0c83f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_df = resampled_df[['avg_queue_density', 'avg_stop_density', 'total_density']]\n",
    "resampled_df = resampled_df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1f5578c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total resampled records: 9469\n",
      "Resampled data range:\n",
      "Start: 2020-09-12 01:30:00\n",
      "End: 2020-12-19 16:30:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_queue_density</th>\n",
       "      <th>avg_stop_density</th>\n",
       "      <th>total_density</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-09-12 01:30:00</th>\n",
       "      <td>0.239704</td>\n",
       "      <td>0.192348</td>\n",
       "      <td>0.432052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-12 01:45:00</th>\n",
       "      <td>0.288713</td>\n",
       "      <td>0.235599</td>\n",
       "      <td>0.524312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-12 02:00:00</th>\n",
       "      <td>0.324898</td>\n",
       "      <td>0.264600</td>\n",
       "      <td>0.589498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-12 02:15:00</th>\n",
       "      <td>0.327211</td>\n",
       "      <td>0.263594</td>\n",
       "      <td>0.590805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-12 02:30:00</th>\n",
       "      <td>0.324831</td>\n",
       "      <td>0.261696</td>\n",
       "      <td>0.586527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     avg_queue_density  avg_stop_density  total_density\n",
       "timestamp                                                              \n",
       "2020-09-12 01:30:00           0.239704          0.192348       0.432052\n",
       "2020-09-12 01:45:00           0.288713          0.235599       0.524312\n",
       "2020-09-12 02:00:00           0.324898          0.264600       0.589498\n",
       "2020-09-12 02:15:00           0.327211          0.263594       0.590805\n",
       "2020-09-12 02:30:00           0.324831          0.261696       0.586527"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Total resampled records:\", resampled_df.shape[0])\n",
    "print(\"Resampled data range:\")\n",
    "print(\"Start:\", resampled_df.index.min())\n",
    "print(\"End:\", resampled_df.index.max())\n",
    "\n",
    "resampled_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885890e6",
   "metadata": {},
   "source": [
    "Outcome of STEP 3:\n",
    "Lane-wise queue density values were averaged to form a single traffic density metric.\n",
    "The per-second data was resampled to hourly averages, significantly reducing noise and creating a stable time-series suitable for deep learning–based traffic flow prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b77921",
   "metadata": {},
   "source": [
    "STEP 4: Feature Engineering and Sequence Creation\n",
    "In this step, time-based features are extracted from the hourly traffic data, and sliding window sequences are created to prepare the dataset for LSTM-based traffic flow prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24992317",
   "metadata": {},
   "outputs": [],
   "source": [
    "ui_df = resampled_df.copy()\n",
    "\n",
    "model_data = resampled_df[['total_density']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28370529",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = resampled_df[['total_density']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a639d935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_raw shape: (9421, 48, 1)\n",
      "y_raw shape: (9421,)\n"
     ]
    }
   ],
   "source": [
    "def create_sequences(data, seq_length=48):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length])\n",
    "        y.append(data[i + seq_length][0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "SEQ_LENGTH = 48\n",
    "X_raw, y_raw = create_sequences(data, SEQ_LENGTH)\n",
    "\n",
    "print(\"X_raw shape:\", X_raw.shape)   # (samples, 48, 1)\n",
    "print(\"y_raw shape:\", y_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e19724fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_future(model, recent_data, steps=8):\n",
    "    preds = []\n",
    "    current = recent_data.copy()\n",
    "\n",
    "    for _ in range(steps):\n",
    "        p = model.predict(current.reshape(1, -1, 1))[0][0]\n",
    "        preds.append(p)\n",
    "        current = np.append(current[1:], p)\n",
    "\n",
    "    return np.array(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1688efe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index = int(0.8 * len(X_raw))\n",
    "\n",
    "X_train_raw, X_test_raw = X_raw[:split_index], X_raw[split_index:]\n",
    "y_train_raw, y_test_raw = y_raw[:split_index], y_raw[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3277928c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final X_train shape: (7536, 48, 1)\n",
      "Final X_test shape: (1885, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 4. Scaling (MODEL ONLY)\n",
    "# ==============================\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale X (fit only on training data)\n",
    "X_train_scaled = scaler.fit_transform(\n",
    "    X_train_raw.reshape(-1, 1)\n",
    ").reshape(X_train_raw.shape)\n",
    "\n",
    "X_test_scaled = scaler.transform(\n",
    "    X_test_raw.reshape(-1, 1)\n",
    ").reshape(X_test_raw.shape)\n",
    "\n",
    "# Scale y using the SAME scaler\n",
    "y_train_scaled = scaler.transform(\n",
    "    y_train_raw.reshape(-1, 1)\n",
    ").ravel()\n",
    "\n",
    "y_test_scaled = scaler.transform(\n",
    "    y_test_raw.reshape(-1, 1)\n",
    ").ravel()\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 5. Final outputs for training\n",
    "# ==============================\n",
    "X_train = X_train_scaled\n",
    "X_test  = X_test_scaled\n",
    "y_train = y_train_scaled\n",
    "y_test  = y_test_scaled\n",
    "\n",
    "print(\"Final X_train shape:\", X_train.shape)\n",
    "print(\"Final X_test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bd7419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Save sequences\n",
    "np.save(\"X_train.npy\", X_train)\n",
    "np.save(\"y_train.npy\", y_train)\n",
    "np.save(\"X_test.npy\", X_test)\n",
    "np.save(\"y_test.npy\", y_test)\n",
    "\n",
    "# Save scaler\n",
    "with open(\"scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b445651",
   "metadata": {},
   "source": [
    "Outcome of STEP 4:\n",
    "Time-based features were added, including hour of day, day of week, and weekend indicator.\n",
    "Data was scaled and converted into sliding window sequences for LSTM training.\n",
    "Training and test sets were created with an 80–20 split, preserving temporal order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f4e24c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract temporal features for UI analytics\n",
    "ui_df = resampled_df.copy()\n",
    "\n",
    "ui_df[\"day_of_week\"] = ui_df.index.day_name()\n",
    "ui_df[\"hour\"] = ui_df.index.hour\n",
    "ui_df[\"minute\"] = ui_df.index.minute\n",
    "\n",
    "# Optional: combine hour & minute for clean labels\n",
    "ui_df[\"time_slot\"] = ui_df.index.strftime(\"%H:%M\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bea17429",
   "metadata": {},
   "outputs": [],
   "source": [
    "ui_df.to_csv(\"data/ui_ready_traffic_data.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
